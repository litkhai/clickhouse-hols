-- ============================================================
-- Bug Bounty Vector Search - Step 5: Integration Guide
-- Python/API í†µí•© ë° í”„ë¡œë•ì…˜ ë°°í¬ ê°€ì´ë“œ
-- ============================================================

/*
ì´ íŒŒì¼ì€ Vector Searchë¥¼ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì— í†µí•©í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ë‚´ìš©:
1. Python í†µí•© ì˜ˆì‹œ (OpenAI, Sentence Transformers)
2. ì‹¤ì‹œê°„ ì„ë² ë”© íŒŒì´í”„ë¼ì¸
3. ë°°ì¹˜ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°
4. ì„±ëŠ¥ ìµœì í™” ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
5. í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
*/

-- ============================================================
-- PART 1: Python + OpenAI API í†µí•©
-- ============================================================

/*
í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
```bash
pip install clickhouse-connect openai python-dotenv
```

í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env):
```
OPENAI_API_KEY=sk-...
CLICKHOUSE_HOST=your-host.clickhouse.cloud
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=your-password
CLICKHOUSE_DATABASE=bug_bounty
```
*/

-- Python ì½”ë“œ ì˜ˆì‹œ 1: OpenAIë¥¼ ì‚¬ìš©í•œ ì„ë² ë”© ìƒì„±
/*
```python
import os
import clickhouse_connect
from openai import OpenAI
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
ch_client = clickhouse_connect.get_client(
    host=os.getenv('CLICKHOUSE_HOST'),
    user=os.getenv('CLICKHOUSE_USER'),
    password=os.getenv('CLICKHOUSE_PASSWORD'),
    database=os.getenv('CLICKHOUSE_DATABASE'),
    secure=True
)

def get_embedding(text: str, model: str = "text-embedding-3-small") -> list[float]:
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
    text = text.replace("\n", " ").strip()

    # OpenAI API í˜¸ì¶œ
    response = openai_client.embeddings.create(
        model=model,
        input=text,
        encoding_format="float"
    )

    return response.data[0].embedding


def embed_http_request(packet_id: str, method: str, uri: str, body: str):
    """HTTP ìš”ì²­ì„ ì„ë² ë”©í•˜ì—¬ ClickHouseì— ì €ì¥"""
    # ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ ìƒì„± (ê¸¸ì´ ì œí•œ)
    normalized = f"{method} {uri}\n{body[:1000]}"

    # ì„ë² ë”© ìƒì„±
    embedding = get_embedding(normalized)

    # ClickHouseì— ì‚½ì…
    ch_client.insert(
        'request_embeddings',
        [[packet_id, normalized, embedding, 'text-embedding-3-small', 1536]],
        column_names=[
            'packet_id', 'normalized_request', 'request_embedding',
            'embedding_model', 'embedding_dim'
        ]
    )

    print(f"âœ“ Embedded request {packet_id}")


def embed_bug_report(
    report_id: str,
    title: str,
    description: str,
    reproduction_steps: str,
    **kwargs
):
    """ë²„ê·¸ ë¦¬í¬íŠ¸ë¥¼ ì„ë² ë”©í•˜ì—¬ ì €ì¥"""
    # ì£¼ìš” ì½˜í…ì¸  ê²°í•©
    content = f"{title}\n\n{description}\n\nReproduction:\n{reproduction_steps}"

    # ì„ë² ë”© ìƒì„±
    embedding = get_embedding(content)

    # ë¦¬í¬íŠ¸ ë°ì´í„° ì¤€ë¹„
    data = {
        'report_id': report_id,
        'title': title,
        'description': description,
        'reproduction_steps': reproduction_steps,
        'content_embedding': embedding,
        'embedding_model': 'text-embedding-3-small',
        'embedding_dim': 1536,
        **kwargs
    }

    # ClickHouseì— ì‚½ì…
    ch_client.insert('report_knowledge_base', [list(data.values())],
                     column_names=list(data.keys()))

    print(f"âœ“ Embedded report {report_id}")


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # HTTP ìš”ì²­ ì„ë² ë”©
    embed_http_request(
        packet_id="550e8400-e29b-41d4-a716-446655440000",
        method="GET",
        uri="/api/users?id=1' OR '1'='1",
        body=""
    )

    # ë²„ê·¸ ë¦¬í¬íŠ¸ ì„ë² ë”©
    embed_bug_report(
        report_id="RPT-2024-009",
        title="SQL Injection in Search API",
        description="The search endpoint is vulnerable to SQL injection...",
        reproduction_steps="1. Navigate to /search\n2. Enter: test' UNION...",
        vulnerability_type="SQLi",
        affected_component="Search API",
        affected_endpoints=["/api/search"],
        reporter_id="hunter_999",
        reported_date="2024-02-01",
        status="SUBMITTED",
        priority="HIGH",
        bounty_amount=0.0
    )
```
*/


-- ============================================================
-- PART 2: ë°°ì¹˜ ì„ë² ë”© íŒŒì´í”„ë¼ì¸
-- ============================================================

/*
ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë°°ì¹˜ íŒŒì´í”„ë¼ì¸

```python
import time
from typing import List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

def batch_embed_requests(batch_size: int = 100, max_workers: int = 5):
    """ë¯¸ì²˜ë¦¬ ìš”ì²­ì„ ë°°ì¹˜ë¡œ ì„ë² ë”©"""

    # ì„ë² ë”©ì´ ì—†ëŠ” ìš”ì²­ ì¡°íšŒ
    query = """
    SELECT p.packet_id, p.request_method, p.request_uri, p.request_body
    FROM bug_bounty.http_packets p
    LEFT JOIN bug_bounty.request_embeddings e ON p.packet_id = e.packet_id
    WHERE e.packet_id IS NULL
    LIMIT {batch_size}
    """

    result = ch_client.query(query.format(batch_size=batch_size))
    rows = result.result_rows

    if not rows:
        print("No pending requests to embed")
        return

    print(f"Processing {len(rows)} requests...")

    # ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = []

        for packet_id, method, uri, body in rows:
            future = executor.submit(
                embed_http_request,
                packet_id, method, uri, body or ""
            )
            futures.append(future)

        # ì™„ë£Œ ëŒ€ê¸°
        for future in as_completed(futures):
            try:
                future.result()
            except Exception as e:
                print(f"Error: {e}")

    print(f"âœ“ Completed batch embedding")


def incremental_embedding_job(interval_seconds: int = 60):
    """ì£¼ê¸°ì ìœ¼ë¡œ ìƒˆ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ëŠ” ì‘ì—…"""
    print(f"Starting incremental embedding job (interval: {interval_seconds}s)")

    while True:
        try:
            batch_embed_requests(batch_size=100)
            time.sleep(interval_seconds)
        except KeyboardInterrupt:
            print("\nStopping...")
            break
        except Exception as e:
            print(f"Error in incremental job: {e}")
            time.sleep(interval_seconds)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë°°ì¹˜ ì²˜ë¦¬
    batch_embed_requests(batch_size=500)

    # ë˜ëŠ” ì§€ì†ì ì¸ ì²˜ë¦¬ (í”„ë¡œë•ì…˜)
    # incremental_embedding_job(interval_seconds=300)  # 5ë¶„ë§ˆë‹¤
```
*/


-- ============================================================
-- PART 3: ì‹¤ì‹œê°„ ìœ ì‚¬ë„ ê²€ìƒ‰ API
-- ============================================================

/*
Vector Searchë¥¼ í™œìš©í•œ REST API ì˜ˆì‹œ

```python
from flask import Flask, request, jsonify
from typing import List, Dict

app = Flask(__name__)

@app.route('/api/search/similar-attacks', methods=['POST'])
def search_similar_attacks():
    """ìœ ì‚¬í•œ ê³µê²© íŒ¨í„´ ê²€ìƒ‰ API"""
    data = request.json
    packet_id = data.get('packet_id')
    top_k = data.get('top_k', 5)

    if not packet_id:
        return jsonify({'error': 'packet_id required'}), 400

    # Vector Search ì¿¼ë¦¬
    query = """
    SELECT
        s.pattern_name,
        s.category,
        s.severity,
        s.cwe_id,
        round(cosineDistance(r.request_embedding, s.payload_embedding), 4) as distance,
        round(1 - cosineDistance(r.request_embedding, s.payload_embedding), 4) as similarity
    FROM bug_bounty.request_embeddings r
    CROSS JOIN bug_bounty.attack_signatures s
    WHERE r.packet_id = {packet_id:UUID}
    ORDER BY distance ASC
    LIMIT {top_k:UInt8}
    """

    result = ch_client.query(
        query,
        parameters={'packet_id': packet_id, 'top_k': top_k}
    )

    matches = [
        {
            'pattern': row[0],
            'category': row[1],
            'severity': row[2],
            'cwe_id': row[3],
            'distance': row[4],
            'similarity': row[5]
        }
        for row in result.result_rows
    ]

    return jsonify({
        'packet_id': packet_id,
        'matches': matches,
        'count': len(matches)
    })


@app.route('/api/reports/check-duplicate', methods=['POST'])
def check_duplicate_report():
    """ì¤‘ë³µ ë¦¬í¬íŠ¸ ê²€ì‚¬ API"""
    data = request.json

    # ìƒˆ ë¦¬í¬íŠ¸ ì½˜í…ì¸ 
    title = data.get('title')
    description = data.get('description')
    reproduction_steps = data.get('reproduction_steps', '')

    # ì„ë² ë”© ìƒì„±
    content = f"{title}\n\n{description}\n\n{reproduction_steps}"
    embedding = get_embedding(content)

    # ìœ ì‚¬ ë¦¬í¬íŠ¸ ê²€ìƒ‰
    query = """
    SELECT
        report_id,
        title,
        vulnerability_type,
        status,
        bounty_amount,
        round(cosineDistance(content_embedding, {embedding:Array(Float32)}), 4) as distance
    FROM bug_bounty.report_knowledge_base
    WHERE status IN ('ACCEPTED', 'FIXED', 'TRIAGED')
      AND distance < 0.4
    ORDER BY distance ASC
    LIMIT 5
    """

    result = ch_client.query(query, parameters={'embedding': embedding})

    duplicates = [
        {
            'report_id': row[0],
            'title': row[1],
            'type': row[2],
            'status': row[3],
            'bounty': float(row[4]),
            'similarity': 1 - row[5]
        }
        for row in result.result_rows
    ]

    is_duplicate = len(duplicates) > 0 and duplicates[0]['similarity'] > 0.8

    return jsonify({
        'is_duplicate': is_duplicate,
        'similar_reports': duplicates,
        'recommendation': 'REJECT' if is_duplicate else 'PROCEED'
    })


@app.route('/api/search/semantic', methods=['POST'])
def semantic_search():
    """ìì—°ì–´ ì¿¼ë¦¬ë¡œ ë¦¬í¬íŠ¸ ê²€ìƒ‰"""
    data = request.json
    query_text = data.get('query')
    top_k = data.get('top_k', 10)

    # ì¿¼ë¦¬ ì„ë² ë”©
    query_embedding = get_embedding(query_text)

    # ê²€ìƒ‰
    search_query = """
    SELECT
        report_id,
        title,
        description,
        vulnerability_type,
        status,
        bounty_amount,
        round(1 - cosineDistance(content_embedding, {embedding:Array(Float32)}), 4) as relevance
    FROM bug_bounty.report_knowledge_base
    WHERE relevance > 0.5
    ORDER BY relevance DESC
    LIMIT {top_k:UInt8}
    """

    result = ch_client.query(
        search_query,
        parameters={'embedding': query_embedding, 'top_k': top_k}
    )

    results = [
        {
            'report_id': row[0],
            'title': row[1],
            'description': row[2][:200] + '...',
            'type': row[3],
            'status': row[4],
            'bounty': float(row[5]),
            'relevance': row[6]
        }
        for row in result.result_rows
    ]

    return jsonify({
        'query': query_text,
        'results': results,
        'count': len(results)
    })


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
```

API ì‚¬ìš© ì˜ˆì‹œ:
```bash
# ìœ ì‚¬ ê³µê²© ê²€ìƒ‰
curl -X POST http://localhost:5000/api/search/similar-attacks \
  -H "Content-Type: application/json" \
  -d '{"packet_id": "550e8400-e29b-41d4-a716-446655440000", "top_k": 5}'

# ì¤‘ë³µ ë¦¬í¬íŠ¸ ê²€ì‚¬
curl -X POST http://localhost:5000/api/reports/check-duplicate \
  -H "Content-Type: application/json" \
  -d '{
    "title": "SQL Injection in Login",
    "description": "Authentication bypass using OR statements...",
    "reproduction_steps": "1. Enter admin OR 1=1..."
  }'

# ì‹œë§¨í‹± ê²€ìƒ‰
curl -X POST http://localhost:5000/api/search/semantic \
  -H "Content-Type: application/json" \
  -d '{"query": "Find reports about authentication bypass", "top_k": 10}'
```
*/


-- ============================================================
-- PART 4: Sentence Transformers (ë¡œì»¬ ì„ë² ë”©)
-- ============================================================

/*
OpenAI API ì—†ì´ ë¡œì»¬ì—ì„œ ì‹¤í–‰ (ë¬´ë£Œ, ì˜¤í”„ë¼ì¸ ê°€ëŠ¥)

ì„¤ì¹˜:
```bash
pip install sentence-transformers
```

Python ì½”ë“œ:
```python
from sentence_transformers import SentenceTransformer
import numpy as np

# ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ ì‹¤í–‰, ìºì‹œë¨)
model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions

def get_local_embedding(text: str) -> list[float]:
    """ë¡œì»¬ ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±"""
    embedding = model.encode(text, convert_to_numpy=True)
    return embedding.tolist()

def embed_with_local_model(packet_id: str, method: str, uri: str, body: str):
    """Sentence Transformersë¥¼ ì‚¬ìš©í•œ ì„ë² ë”©"""
    normalized = f"{method} {uri}\n{body[:1000]}"
    embedding = get_local_embedding(normalized)

    ch_client.insert(
        'request_embeddings',
        [[packet_id, normalized, embedding, 'all-MiniLM-L6-v2', 384]],
        column_names=[
            'packet_id', 'normalized_request', 'request_embedding',
            'embedding_model', 'embedding_dim'
        ]
    )

# ì¥ì :
# - ë¬´ë£Œ, ì˜¤í”ˆì†ŒìŠ¤
# - API í˜¸ì¶œ ì œí•œ ì—†ìŒ
# - ì˜¤í”„ë¼ì¸ ì‘ë™
# - ë‚®ì€ ë ˆì´í„´ì‹œ

# ë‹¨ì :
# - OpenAIë³´ë‹¤ ë‚®ì€ ì •í™•ë„ (ì¼ë°˜ì ìœ¼ë¡œ)
# - GPU ê¶Œì¥ (CPUë„ ê°€ëŠ¥í•˜ì§€ë§Œ ëŠë¦¼)
# - ëª¨ë¸ í¬ê¸° (ìˆ˜ë°± MB)
```
*/


-- ============================================================
-- PART 5: ì„±ëŠ¥ ìµœì í™” íŒ
-- ============================================================

/*
1. ì„ë² ë”© ìºì‹± ì „ëµ
```python
import hashlib
from functools import lru_cache

@lru_cache(maxsize=10000)
def get_embedding_cached(text: str) -> tuple:
    """ìºì‹œëœ ì„ë² ë”© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )"""
    embedding = get_embedding(text)
    return tuple(embedding)  # ë¦¬ìŠ¤íŠ¸ëŠ” ìºì‹œ ë¶ˆê°€, íŠœí”Œë¡œ ë³€í™˜

# ë˜ëŠ” Redis ì‚¬ìš©
import redis
r = redis.Redis(host='localhost', port=6379, db=0)

def get_embedding_redis_cached(text: str) -> list[float]:
    """Redis ìºì‹œ ì‚¬ìš©"""
    cache_key = f"emb:{hashlib.md5(text.encode()).hexdigest()}"

    # ìºì‹œ í™•ì¸
    cached = r.get(cache_key)
    if cached:
        return eval(cached)  # ì£¼ì˜: í”„ë¡œë•ì…˜ì—ì„œëŠ” pickle ë˜ëŠ” json ì‚¬ìš©

    # ìºì‹œ ë¯¸ìŠ¤, ì„ë² ë”© ìƒì„±
    embedding = get_embedding(text)

    # ìºì‹œ ì €ì¥ (24ì‹œê°„)
    r.setex(cache_key, 86400, str(embedding))

    return embedding
```

2. ë°°ì¹˜ ì„ë² ë”© ìµœì í™”
```python
def batch_get_embeddings(texts: List[str]) -> List[list[float]]:
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ í•œ ë²ˆì— ì„ë² ë”© (ë” íš¨ìœ¨ì )"""
    # OpenAIëŠ” ë°°ì¹˜ë¥¼ ì§€ì›
    response = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=texts  # ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
    )

    return [item.embedding for item in response.data]

# ì‚¬ìš©
texts = ["text1", "text2", "text3"]
embeddings = batch_get_embeddings(texts)
```

3. ClickHouse ì¿¼ë¦¬ ìµœì í™”
```sql
-- ì˜ëª»ëœ ì˜ˆ: ëª¨ë“  ë°ì´í„° ìŠ¤ìº”
SELECT * FROM request_embeddings r
CROSS JOIN attack_signatures s
WHERE cosineDistance(r.request_embedding, s.payload_embedding) < 0.5;

-- ì˜¬ë°”ë¥¸ ì˜ˆ: WHEREë¡œ í›„ë³´êµ° ë¨¼ì € í•„í„°ë§
SELECT * FROM request_embeddings r
CROSS JOIN attack_signatures s
WHERE r.created_at >= today() - 7  -- ìµœê·¼ 7ì¼ë§Œ
  AND s.severity IN ('CRITICAL', 'HIGH')  -- ê³ ìœ„í—˜ë§Œ
  AND cosineDistance(r.request_embedding, s.payload_embedding) < 0.5;
```

4. íŒŒí‹°ì…”ë‹ ì „ëµ
```sql
-- ì‹œê°„ ê¸°ë°˜ íŒŒí‹°ì…”ë‹ ì¶”ê°€
ALTER TABLE request_embeddings
    MODIFY SETTING partition_by = toYYYYMM(created_at);

-- ì˜¤ë˜ëœ íŒŒí‹°ì…˜ ì‚­ì œ (ìŠ¤í† ë¦¬ì§€ ì ˆì•½)
ALTER TABLE request_embeddings DROP PARTITION '202401';
```
*/


-- ============================================================
-- PART 6: í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
-- ============================================================

/*
[ ] 1. ì„ë² ë”© ëª¨ë¸ ì„ íƒ
    - OpenAI text-embedding-3-small (1536 dim) - ë†’ì€ ì •í™•ë„
    - OpenAI text-embedding-3-large (3072 dim) - ìµœê³  ì •í™•ë„, ë¹„ìš© ì¦ê°€
    - Sentence Transformers all-MiniLM-L6-v2 (384 dim) - ë¬´ë£Œ, ë‚®ì€ ì •í™•ë„
    - ê¸°ì—…ìš© ëª¨ë¸ (Cohere, Voyage AI ë“±)

[ ] 2. ì¸í”„ë¼ ê³ ë ¤ì‚¬í•­
    - API í‚¤ ë³´ì•ˆ ê´€ë¦¬ (AWS Secrets Manager, HashiCorp Vault)
    - Rate limiting (OpenAI: 3000 RPM, 1M TPM)
    - ì‹¤íŒ¨ ì²˜ë¦¬ ë° ì¬ì‹œë„ ë¡œì§
    - ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ (Grafana, Prometheus)

[ ] 3. ë°ì´í„° í’ˆì§ˆ
    - í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
    - ê¸¸ì´ ì œí•œ (OpenAI: 8191 tokens)
    - ì–¸ì–´ë³„ ì²˜ë¦¬ (ë‹¤êµ­ì–´ ì§€ì› í•„ìš” ì‹œ)
    - ì¤‘ë³µ ì œê±° (ê°™ì€ í…ìŠ¤íŠ¸ ë°˜ë³µ ì„ë² ë”© ë°©ì§€)

[ ] 4. ì„±ëŠ¥ ìµœì í™”
    - ë°°ì¹˜ ì²˜ë¦¬ (ë‹¨ì¼ ìš”ì²­ë³´ë‹¤ íš¨ìœ¨ì )
    - ìºì‹± (Redis, Memcached)
    - ë¹„ë™ê¸° ì²˜ë¦¬ (Celery, RabbitMQ)
    - íŒŒí‹°ì…”ë‹ (ì‹œê°„, ì¹´í…Œê³ ë¦¬ ë“±)

[ ] 5. ë¹„ìš© ìµœì í™”
    - OpenAI embedding ë¹„ìš©: $0.00002 / 1K tokens
    - ì›” 100ë§Œ ìš”ì²­ = ì•½ $20 (í‰ê·  1K tokens)
    - ìºì‹±ìœ¼ë¡œ ì¤‘ë³µ ìš”ì²­ ë°©ì§€
    - ë¶ˆí•„ìš”í•œ ì„ë² ë”© ì œê±° (TTL ì„¤ì •)

[ ] 6. ë³´ì•ˆ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤
    - PII ë°ì´í„° ë§ˆìŠ¤í‚¹ (ì„ë² ë”© ì „)
    - API í‚¤ ë¡œí…Œì´ì…˜
    - ë°ì´í„° ì•”í˜¸í™” (ì „ì†¡ ì¤‘, ì €ì¥ ì‹œ)
    - ê°ì‚¬ ë¡œê·¸ (ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„)

[ ] 7. ë°±ì—… ë° ë³µêµ¬
    - ì„ë² ë”© ë°ì´í„° ë°±ì—… (S3, GCS)
    - ì¬ìƒì„± ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    - ì¬í•´ ë³µêµ¬ ê³„íš (DR plan)

[ ] 8. ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­
    - ì„ë² ë”© ìƒì„± ë ˆì´í„´ì‹œ
    - API í˜¸ì¶œ ì„±ê³µ/ì‹¤íŒ¨ìœ¨
    - ê²€ìƒ‰ ì •í™•ë„ (precision, recall)
    - ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©ëŸ‰
    - ë¹„ìš© ì¶”ì 
*/


-- ============================================================
-- PART 7: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
-- ============================================================

-- ì„ë² ë”© í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
CREATE OR REPLACE VIEW bug_bounty.v_embedding_quality_test AS
WITH test_pairs AS (
    -- ê°™ì€ ì¹´í…Œê³ ë¦¬ (ìœ ì‚¬í•´ì•¼ í•¨)
    SELECT
        'Same Category' as pair_type,
        s1.pattern_name as pattern_1,
        s2.pattern_name as pattern_2,
        cosineDistance(s1.payload_embedding, s2.payload_embedding) as distance,
        'PASS' as expected
    FROM bug_bounty.attack_signatures s1
    JOIN bug_bounty.attack_signatures s2
        ON s1.category = s2.category
        AND s1.signature_id < s2.signature_id

    UNION ALL

    -- ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ (ë‹¤ë¥´ì–´ì•¼ í•¨)
    SELECT
        'Different Category' as pair_type,
        s1.pattern_name as pattern_1,
        s2.pattern_name as pattern_2,
        cosineDistance(s1.payload_embedding, s2.payload_embedding) as distance,
        'PASS' as expected
    FROM bug_bounty.attack_signatures s1
    JOIN bug_bounty.attack_signatures s2
        ON s1.category != s2.category
        AND s1.signature_id < s2.signature_id
)
SELECT
    pair_type,
    count() as total_pairs,
    round(avg(distance), 4) as avg_distance,
    round(min(distance), 4) as min_distance,
    round(max(distance), 4) as max_distance,
    multiIf(
        pair_type = 'Same Category' AND avg(distance) < 0.5, 'PASS',
        pair_type = 'Different Category' AND avg(distance) > 0.5, 'PASS',
        'FAIL'
    ) as test_result
FROM test_pairs
GROUP BY pair_type;

-- í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
SELECT * FROM bug_bounty.v_embedding_quality_test
FORMAT PrettyCompactMonoBlock;


-- ============================================================
-- ë§ˆë¬´ë¦¬
-- ============================================================

/*
ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰

Vector Search ì‹¤ìŠµì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ì´ì œ ë‹¤ìŒì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

âœ“ ê³µê²© íŒ¨í„´ ì‹œê·¸ë‹ˆì²˜ ì €ì¥ ë° ê´€ë¦¬
âœ“ HTTP ìš”ì²­ ì„ë² ë”© ìƒì„± ë° ê²€ìƒ‰
âœ“ ë²„ê·¸ ë¦¬í¬íŠ¸ ì‹œë§¨í‹± ê²€ìƒ‰
âœ“ ì¤‘ë³µ ë¦¬í¬íŠ¸ ìë™ íƒì§€
âœ“ Python/API í†µí•©
âœ“ í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„

ë‹¤ìŒ ë‹¨ê³„:
1. ì‹¤ì œ OpenAI API í‚¤ë¡œ í…ŒìŠ¤íŠ¸
2. í”„ë¡œë•ì…˜ ë°ì´í„°ë¡œ ê²€ì¦
3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
4. CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì„±
5. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì„¤ì •

ì°¸ê³  ìë£Œ:
- ClickHouse Vector Search: https://clickhouse.com/docs/en/engines/table-engines/mergetree-family/annindexes
- OpenAI Embeddings: https://platform.openai.com/docs/guides/embeddings
- Sentence Transformers: https://www.sbert.net/

ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±: https://github.com/ClickHouse/ClickHouse/discussions
*/

-- ============================================================
-- END OF VECTOR SEARCH LAB
-- ============================================================
