bucket_arn = "arn:aws:s3:::clickhouse-s3-direct-test-20251205"
bucket_domain_name = "clickhouse-s3-direct-test-20251205.s3.amazonaws.com"
bucket_name = "clickhouse-s3-direct-test-20251205"
bucket_region = "ap-northeast-2"
clickhouse_iam_role_arns = tolist([
  "arn:aws:iam::277707138598:role/CH-S3-orangeaws-ba-92-an2-fb-Role",
])
clickhouse_sql_examples = <<EOT
-- Example 1: Create S3-backed table (Parquet format) - Direct Access
CREATE TABLE logs_s3
(
    timestamp DateTime,
    level String,
    message String
)
ENGINE = S3(
    'https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205/logs/app_logs.parquet',
    'Parquet'
);

-- Example 2: Create S3-backed table (CSV format) - Direct Access
CREATE TABLE events_s3
(
    event_id UInt64,
    user_id String,
    event_type String,
    created_at DateTime
)
ENGINE = S3(
    'https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205/data/events.csv',
    'CSV'
);

-- Example 3: Create S3-backed table (JSON format with wildcard) - Direct Access
CREATE TABLE user_activity_s3
(
    user_id String,
    action String,
    timestamp DateTime
)
ENGINE = S3(
    'https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205/data/user_activity_*.json',
    'JSONEachRow'
);

-- Example 4: Direct query without creating table - Direct Access
SELECT * FROM s3(
    'https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205/data/*.parquet'
) LIMIT 10;

-- Example 5: Insert data to S3
INSERT INTO logs_s3 VALUES
    (now(), 'INFO', 'Application started'),
    (now(), 'DEBUG', 'Processing request'),
    (now(), 'ERROR', 'Connection timeout');

-- Example 6: Export query results to S3 - Direct Access
INSERT INTO FUNCTION s3(
    'https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205/exports/query_result.parquet',
    'Parquet',
    'user_id String, total_events UInt64'
)
SELECT user_id, count() AS total_events
FROM user_activity_s3
GROUP BY user_id;

EOT
connection_info = <<EOT
================================================================================
ClickHouse Cloud S3 Configuration (Direct Bucket Policy Access)
================================================================================

S3 Bucket Information:
  Bucket Name:       clickhouse-s3-direct-test-20251205
  Bucket ARN:        arn:aws:s3:::clickhouse-s3-direct-test-20251205
  Region:            ap-northeast-2
  S3 URL:            https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205

Access Method:
  Type:              Direct S3 Bucket Policy (No AssumeRole)
  Allowed ARNs:      arn:aws:iam::277707138598:role/CH-S3-orangeaws-ba-92-an2-fb-Role

ClickHouse S3 Table Engine Example (No extra_credentials needed):
  -- Create table with S3 engine (direct access)
  CREATE TABLE s3_table
  (
      id UInt64,
      name String,
      timestamp DateTime
  )
  ENGINE = S3(
      'https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205/data/table_data.parquet',
      'Parquet'
  );

  -- Insert data to S3
  INSERT INTO s3_table VALUES (1, 'example', now());

  -- Query data from S3
  SELECT * FROM s3_table;

ClickHouse S3 Function Example (No extra_credentials needed):
  -- Query Parquet file directly
  SELECT * FROM s3(
      'https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205/data/*.parquet'
  );

  -- Insert data to S3 using s3() function
  INSERT INTO FUNCTION s3(
      'https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205/data/output.parquet',
      'Parquet',
      'id UInt64, name String, timestamp DateTime'
  )
  SELECT 1 AS id, 'test' AS name, now() AS timestamp;

================================================================================

EOT
s3_url_prefix = "https://s3.ap-northeast-2.amazonaws.com/clickhouse-s3-direct-test-20251205"
setup_checklist = <<EOT
================================================================================
Setup Checklist (Direct S3 Bucket Policy Access)
================================================================================

AWS Setup (Completed by Terraform):
  ✓ S3 bucket created: clickhouse-s3-direct-test-20251205
  ✓ S3 bucket policy created with direct ARN access
  ✓ S3 permissions configured (read + write)
  ✓ Bucket encryption enabled
  ✓ Public access settings configured

ClickHouse Cloud Setup (Manual Steps):
  1. Log into ClickHouse Cloud Console
  2. Select your service
  3. Navigate to: Settings → Network security information
  4. Copy the "Service role ID (IAM)" value
  5. Verify it matches one of the ARNs in your terraform.tfvars:
     arn:aws:iam::277707138598:role/CH-S3-orangeaws-ba-92-an2-fb-Role

Testing Steps:
  1. Connect to your ClickHouse Cloud instance
  2. Copy SQL examples from the 'clickhouse_sql_examples' output
  3. Execute the SQL to create S3-backed tables (NO extra_credentials needed!)
  4. Insert test data
  5. Query the data to verify
  6. Check S3 bucket for created files

Key Differences from AssumeRole Method:
  • No IAM role creation - uses direct S3 bucket policy
  • No extra_credentials() needed in SQL queries
  • Simpler SQL syntax
  • Direct access from ClickHouse IAM role to S3 bucket

Troubleshooting:
  - If you get "Access Denied" errors:
    • Verify ClickHouse IAM role ARN is correct
    • Check S3 bucket policy in AWS Console
    • Ensure S3 bucket is in the same region as ClickHouse Cloud
  - If you get "Bucket not found" errors:
    • Verify S3 URL format
    • Check bucket name spelling
    • Ensure bucket region matches

================================================================================

EOT
